set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
makeVector()
v <-makeVector()
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
cachemean(c(1:10))
v <- makeVector(c(1:10))
cachemean(v)
cachemean(v)
cachemean(v)
matrix()
makeVector <- function(x = matrix()) {
inv <- NULL
set <- function(y) {
x <<- y
inv <<- NULL
}
get <- function() x
setinverse <- function(inverse) inv <<- inverse
getinverse <- function() m
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
cachemean <- function(x, ...) {
inv <- x$getinverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data,...)
x$setmean(inv)
inv
}
mat <- matrix(c(1:4), nrow = 2, ncol=2)
makeVector(mat)
vec <- makeVector(mat)
cachemean(vec)
makeVector <- function(x = matrix()) {
inv <- NULL
set <- function(y) {
x <<- y
inv <<- NULL
}
get <- function() x
setinverse <- function(inverse) inv <<- inverse
getinverse <- function() inv
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
cachemean <- function(x, ...) {
inv <- x$getinverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data,...)
x$setmean(inv)
inv
}
mat <- matrix(c(1:4), nrow = 2, ncol=2)
vec <- makeVector(mat)
cachemean(vec)
vec
cachemean <- function(x, ...) {
inv <- x$getinverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data)
x$setmean(inv)
inv
}
cachemean(vec)
vec$get()
vec$set()
cachemean <- function(x, ...) {
inv <- x$getinverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data)
x$setinverse(inv)
inv
}
cachemean(vec)
mat <- matrix(c(1:10000), nrow= 100, rcol=100)
mat <- matrix(c(1:10000), nrow= 100, ncol=100)
vec <- makeVector(mat)
cachemean(vec)
mat
cachemean(vec)
mat <- matrix(rnorm(1000) , nrow= 100, ncol=100)
makeVector(mat)
vec <- makeVector(mat)
cachemean(vec)
det(mat)
mat <- matrix(c(1:100), nrow=10, ncol=10)
vec <- makeVector(mat)
cachemean(vec)
det(mat)
mat <- matrix(c(1:9), nrow= 3, ncol=3)
det(mat)
mat <- matrix(c(1:4), nrow= 2, ncol=2)
x <- mtcars
x
group_by(x,cyl)
summarise(group_by(x,cyl), mpg = mean(mpg))
grp<- group_by(x, cyl)
slice(grp, 1:2)
ls ()
rm(list = ls())
library(nycflights13)
x < flights
x <- flights
x
x.grp.plane <- group_by(x, tailnum)
summarise(x.grp.plane, distance = sum(distance, na.rm = TRUE), arr_delay = mean(arr_delay, na.rm = TRUE), air_time= mean(air_time, na.rm = TRUE))
sum <-summarise(x.grp.plane, distance = sum(distance, na.rm = TRUE), arr_delay = mean(arr_delay, na.rm = TRUE), air_time= mean(air_time, na.rm = TRUE))
cor(sum$arr_delay, sum$air_time)
n()
?n
cor(sum$arr_delay, sum$air_time, na.rm =TRUE)
cor(sum$arr_delay, sum$air_time, use = 'complete')
plot(sum$distance, sum$arr_delay)
plot(sum$air_time, sum$arr_delay)
x
summarise(group_by(x,dest)), flights = n_distinct(tailnum), total = n())
summarise(group_by(x,dest), flights = n_distinct(tailnum), total = n())
summarise(group_by(x, year,month), total= n())
sum <- summarise(group_by(x, year,month), total= n())
barplot(sum$total, names.arg = sum$month)
barplot(sum$total, names.arg = sum$month, xlab = 'months', ylab = 'total number of flights')
x
filter(x, tailnum = 'N14228')
filter(x, tailnum == 'N14228')
flight_N14228 <- filter(x, tailnum == 'N14228')
flight_N14228
group_by(flight_N14228,month,day)
group_by(flight_N14228,month,day) %>%
summary( total = n())
group_by(flight_N14228,month,day) %>%
summarise(total = n())
group_by(flight_N14228,month,day) %>%
+ summarise(total = n()) %>%
n_distinct(days)
group_by(flight_N14228,month,day) %>%
+ summarise(total = n()) %>%
%>%
group_by(flight_N14228,month,day) %>%
+ summarise(total = n())
group_by(flight_N14228, day) %>%
summarise(count = n())
group_by(flight_N14228, day) %>%
summarise(count = n())%>%
as.data.frame()
df <- group_by(flight_N14228, day) %>%
summarise(count = n())%>%
as.data.frame()
sum(df$count)
library(rvest)
url <- html('http://www.visitithaca.com/attractions/wineries.html')
brewries <- html_nodes(url,'.indSearchListingTitle a') %>%
html_text()
brewries
adresses<- html_nodes(url,'.indMetaWrapper:nth-child(1) .indMetaInfoWrapper')%>%
html_text()
adresses
?gsub
gsub
gsub("\n",'',adresses)
gsub(c(\n, '',  ),'',adresses)
gsub('"','',adresses)
gsub('\\t','',adresses)
gsub('\\n','',adresses)
gsub('\\s','',adresses)
adresses<-gsub('\\n','',adresses)
adresses<-gsub('ontheCayugalLakeWineTrail','',adresses, ignore.case = TRUE)
adressess
adresses
adresses<-gsub('\\s','',adresses)
adresses<-gsub('ontheCayugalLakeWineTrail','',adresses, ignore.case = TRUE)
adresses
adresses<-gsub('ontheCayugaLakeWineTrail','',adresses, ignore.case = TRUE)
adresses
adresses<-gsub('\\W','',adresses, ignore.case = TRUE)
adresses
s <- c('chirag', 'dinesh','karan')
sapply(s, paste,sep = "bb")
sapply(s, function(x) x + 'a')
sapply(s, function(x) paste(x,'a',sep = '_'))
rm
rm(list = ls())
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL
set <- function(y) {
x <<- y
inv <<- NULL
}
get <- function() x
setinverse <- function(inverse) inv <<- inverse
getinverse <- function() inv
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
cacheSolve <- function(x, ...) {
inv <- x$getinverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data)
x$setinverse(inv)
inv
}
makeCacheMatrix(matrix(c(1:4), nrow = 2, ncol = 2))
mat <- makeCacheMatrix(matrix(c(1:4), nrow = 2, ncol = 2))
cacheSolve(mat)
cacheSolve(mat)
close()
x <- c(7921, 5184,8836,4761)
range(x)
x <- x/(8836-4761)
x
summary(x)
x <- (x- 1.638)/(2.168-1.168)
x
who
ls
ls()
rm(x)
ls()
?quantile
?cut
install.packages('ggplot2')
library('ggplot2')
library('datasets')
mtcars
ggplot(mtcars,aes(x = factor(mtcars$cyl), y = mpg))
ggplot(mtcars,aes(x = factor(mtcars$cyl), y = mpg)) + geom_point()
ggplot(mtcars,aes(x = factor(mtcars$cyl), y = mpg, col = disp)) + geom_point()
ggplot(mtcars,aes(x = factor(mtcars$cyl), y = mpg, col = disp, size=disp)) + geom_point()
ggplot(mtcars,aes(x = wt, y = mpg, col = disp, size=disp)) + geom_point()
iris
diamonds
cor(diamonds$carat,diamonds$price, na.rm= TRUE)
cor(diamonds$carat,diamonds$price)
x <- diamonds
ggplot(x, aes(x = x$carat, y= x$price))+ geom_point()
y <- diamonds
z <- diamonds
ggplot(x, aes(x = z$carat, y= z$price))+ geom_point()
data <- diamonds
rm(list = ls())
dat <- diamonds
ggplot(dat, aes(x=dat$carat, y=dat$price)) + geom_point()
dat <- dat[1:1000,]
ggplot(dat, aes(x=dat$carat, y=dat$price)) + geom_point()
dat
dat <- diamonds
ggplot(dat, aes(x=dat$carat, y=dat$price)) + geom_point()
str(dat)
ggplot(dat, aes(x=dat$carat, y=dat$price)) + geom_point() + geom_smooth()
str(dat)
dat <- mtcars
as.list(as.factor(dat$cyl))
dat$cyl <- as.factor(dat$cyl)
lapply(dat$cyl, function(x){print(x)})
ggplot(mtcars, aes(x = wt, y = mpg, col = cyl)) + geom_point()
ggplot(dat, aes(x = wt, y = mpg, col = cyl)) + geom_point()
cor(dat$cyl,dat$wt)
barplot(dat$cyl)
ggplot(mtcars, aes(x = wt, y = mpg, col = cyl)) + geom_point()+ geom_smooth(method='lm', se=FALSE)
ggplot(mtcars, aes(x = wt, y = mpg, col = cyl)) + geom_point()+ geom_smooth(method='lm', se=TRUE)
ggplot(mtcars, aes(x = wt, y = mpg, col = cyl)) + geom_point()+ geom_smooth(method='lm')
ggplot(mtcars, aes(x = wt, y = mpg, col = cyl)) + geom_point()+ geom_smooth(method='glm')
ggplot(data = , aes(x = wt, y = mpg, col = cyl)) + geom_point()+ geom_smooth(method='lm', se= FALSE)
ggplot(dat , aes(x = wt, y = mpg, col = cyl)) + geom_point()+ geom_smooth(method='lm', se= FALSE)
ggplot(dat , aes(x = wt, y = mpg, col = cyl)) + geom_point()+ geom_smooth( se= FALSE)
ggplot(dat , aes(x = wt, y = mpg)) + geom_point()+ geom_smooth( se= FALSE)
dat <- iris
head(dat)
ggplot(dat, aes(x= Species, y= Petal.Width))
ggplot(dat, aes(x= Species, y= Petal.Width)) + geom_point()
ggplot(dat, aes(x= Species, y= Petal.Width, col = Species) + geom_point()
ggplot(dat, aes(x= Species, y= Petal.Width, col = Species)) + geom_point()
class(dat$Species)
ggplot(dat, aes(x= Species, y= Petal.Width, col = Species)) + geom_jitter()
ggplot(dat, aes(x= Species, y= Petal.Length, col = Species)) + geom_jitter() + facet_grid(.~Petal.Width)
ggplot(dat, aes(x= Species, y= Petal.Length, col = Species)) + geom_jitter() + facet_grid(Petal.Width)
ggplot(dat, aes(x= Species, y= Petal.Length, col = Species)) + geom_jitter() + facet_grid(.~Petal.Width)
install.packages('tidyr')
library('tidyr')
library(dplyr)
df <- data_frame(
group = c(1:2, 1),
item_id = c(1:2, 2),
item_name = c("a", "b", "b"),
value1 = 1:3,
value2 = 4:6
)
df %>% complete(group, nesting(item_id, item_name))
getwd()
rm(list = ls())
library(dplyr)
library(ggplot2)
#Setting the Appropriate Working Directory
setwd('C:/Users/chirag/Downloads/Analytics Vidya Problems Datasets/Big Mart sales problem')
# reading the training and Test Datasets
train <- read.csv('Train.csv', na.strings = "")
test <- read.csv('Test.csv',na.strings = "")
test$Item_Outlet_Sales <- NA
train$flag <- 'train'
test$flag <- 'test'
data.all <- rbind(train,test)
# find the number of missing values for each variable
sapply(data.all, function(x) sum(is.na(x)))
#find the classes of each column
sapply(data.all,class)
summary(data.all)
# finding the colums with numerical data
numerical_col <- names(train)[sapply(train,is.numeric)]
# Getting the number of unique values in each column or variable
data.all %>% sapply(function(x) length(unique(x)))
# Getting unique values for factor variables
data.all %>% select(-one_of(numerical_col),-Item_Identifier,-flag)%>%
sapply(function(x) unique(x))
# Getting frequency of levels for each categorical variables
data.all %>% select(-one_of(numerical_col),-Item_Identifier,-flag)%>%
sapply(function(x) table(x))
# cleaning up the factor variable Item_Fat_Content
data.all$Item_Fat_Content[data.all$Item_Fat_Content %in% c('low fat','LF')]= 'Low Fat'
data.all$Item_Fat_Content[data.all$Item_Fat_Content %in% c('reg')]= 'Regular'
# MISSING VALUE TREATMENT
# treating missing values for Item_Weight
index <- !complete.cases(data.all$Item_Weight)
Item_IDs <- unique(data.all[index,]$Item_Identifier)
# replacing each missing item weight value with the mean of the item weight across that item category
for(i in 1:length(Item_IDs)){
if(data.all %>% filter(Item_Identifier==Item_IDs[i],is.na(Item_Weight)) %>% nrow() >0){
data.all[data.all$Item_Identifier==Item_IDs[i] & is.na(data.all$Item_Weight),'Item_Weight']<- mean(data.all[data.all$Item_Identifier==Item_IDs[i],]$Item_Weight, na.rm = TRUE)
}
}
# Treating 0 item_visbility as NA and applying missing value treatment on it
for(i in 1:length(Item_IDs)){
if(data.all %>% filter(Item_Identifier==Item_IDs[i],Item_Visibility==0) %>% nrow() >0){
data.all[data.all$Item_Identifier==Item_IDs[i] & data.all$Item_Visibility==0,'Item_Visibility']<- mean(data.all[data.all$Item_Identifier==Item_IDs[i],]$Item_Visibility, na.rm = TRUE)
}
}
# missing value treatment for Outlet Size
data.all %>% sapply(function(x) length(unique(x)))
OutletTypes <- levels(data.all$Outlet_Type )
for(i in 1:length(OutletTypes)){
if(data.all %>% filter(Outlet_Type==OutletTypes[i],is.na(Outlet_Size)) %>% nrow() >0){
data.all[data.all$Outlet_Type==OutletTypes[i] & is.na(data.all$Outlet_Size),'Outlet_Size']<- names(desc(table(data.all[data.all$Outlet_Type==OutletTypes[1] & !is.na(data.all$Outlet_Size) ,]$Outlet_Size)))[1]
}
}
#------------------------------------------------------------------------------------------
#dropping the unused factors
data.all$Item_Fat_Content <- droplevels(data.all$Item_Fat_Content)
train <- data.all %>% filter(flag=='train') %>% select(-flag)
test <- data.all %>% filter(flag=='test') %>% select(-flag)
#BUILDING A LINEAR MODEL
model <- glm(Item_Outlet_Sales ~ as.factor(Item_Fat_Content)+ Item_Weight + Item_Visibility + Item_Type+ Item_MRP + as.factor(Outlet_Identifier) + Outlet_Establishment_Year + as.factor(Outlet_Size) + as.factor(Outlet_Location_Type) + as.factor(Outlet_Type), data = train)
# GETTING THE PREDICTED VALUES
predictedvalues <- predict(model,newdata = test)
test <- cbind(test,predictedvalues)
submission <- read.csv('SampleSubmission.csv')
submission$Item_Outlet_Sales <- predictedvalues
write.csv(submission,'PredictedValues.csv')
library(rpart)
library(rpart.plot)
library(randomForest)
str(train)
ForestModel <- randomForest(Item_Outlet_Sales ~ Item_Fat_Content+ Item_Weight + Item_Visibility + Item_Type+ Item_MRP + as.factor(Outlet_Identifier) + Outlet_Establishment_Year + Outlet_Size + Outlet_Location_Type + Outlet_Type, data = train, ntree=200, nodesize=25)
ForestModel <- randomForest(Item_Outlet_Sales ~ Item_Fat_Content+ Item_Weight + Item_Visibility + Item_Type+ Item_MRP + Outlet_Identifier + Outlet_Establishment_Year + Outlet_Size + Outlet_Location_Type + Outlet_Type, data = train, ntree=200, nodesize=25)
predictedvalues <- predict(model,newdata = test)
predictedvalues <- predict(ForestModel,newdata = test)
test <- cbind(test,predictedvalues)
submission <- read.csv('SampleSubmission.csv')
submission$Item_Outlet_Sales <- predictedvalues
write.csv(submission,'PredictedValues.csv')
write.csv(submission,'PredictedValues.csv')
cartModel <- rpart(Item_Outlet_Sales ~ Item_Fat_Content+ Item_Weight + Item_Visibility + Item_Type+ Item_MRP + Outlet_Identifier + Outlet_Establishment_Year + Outlet_Size + Outlet_Location_Type + Outlet_Type, data = train, minbucket=25)
predictedvalues <- predict(ForestModel,newdata = test)
test <- cbind(test,predictedvalues)
submission <- read.csv('SampleSubmission.csv')
submission$Item_Outlet_Sales <- predictedvalues
write.csv(submission,'PredictedValues.csv')
rm(list = ls())
library(dplyr)
library(ggplot2)
#Setting the Appropriate Working Directory
setwd('C:/Users/chirag/Downloads/Analytics Vidya Problems Datasets/Big Mart sales problem')
# reading the training and Test Datasets
train <- read.csv('Train.csv', na.strings = "")
test <- read.csv('Test.csv',na.strings = "")
test$Item_Outlet_Sales <- NA
train$flag <- 'train'
test$flag <- 'test'
data.all <- rbind(train,test)
# find the number of missing values for each variable
sapply(data.all, function(x) sum(is.na(x)))
#find the classes of each column
sapply(data.all,class)
summary(data.all)
# finding the colums with numerical data
numerical_col <- names(train)[sapply(train,is.numeric)]
# Getting the number of unique values in each column or variable
data.all %>% sapply(function(x) length(unique(x)))
# Getting unique values for factor variables
data.all %>% select(-one_of(numerical_col),-Item_Identifier,-flag)%>%
sapply(function(x) unique(x))
# Getting frequency of levels for each categorical variables
data.all %>% select(-one_of(numerical_col),-Item_Identifier,-flag)%>%
sapply(function(x) table(x))
# cleaning up the factor variable Item_Fat_Content
data.all$Item_Fat_Content[data.all$Item_Fat_Content %in% c('low fat','LF')]= 'Low Fat'
data.all$Item_Fat_Content[data.all$Item_Fat_Content %in% c('reg')]= 'Regular'
# converting outlet extablishment year to the toal no of years it has been open
data.all$Outlet_Establishment_Year <- 2016 - data.all$Outlet_Establishment_Year
# MISSING VALUE TREATMENT
# treating missing values for Item_Weight
index <- !complete.cases(data.all$Item_Weight)
Item_IDs <- unique(data.all[index,]$Item_Identifier)
# replacing each missing item weight value with the mean of the item weight across that item category
for(i in 1:length(Item_IDs)){
if(data.all %>% filter(Item_Identifier==Item_IDs[i],is.na(Item_Weight)) %>% nrow() >0){
data.all[data.all$Item_Identifier==Item_IDs[i] & is.na(data.all$Item_Weight),'Item_Weight']<- mean(data.all[data.all$Item_Identifier==Item_IDs[i],]$Item_Weight, na.rm = TRUE)
}
}
# Treating 0 item_visbility as NA and applying missing value treatment on it
for(i in 1:length(Item_IDs)){
if(data.all %>% filter(Item_Identifier==Item_IDs[i],Item_Visibility==0) %>% nrow() >0){
data.all[data.all$Item_Identifier==Item_IDs[i] & data.all$Item_Visibility==0,'Item_Visibility']<- mean(data.all[data.all$Item_Identifier==Item_IDs[i],]$Item_Visibility, na.rm = TRUE)
}
}
# missing value treatment for Outlet Size
data.all %>% sapply(function(x) length(unique(x)))
OutletTypes <- levels(data.all$Outlet_Type )
for(i in 1:length(OutletTypes)){
if(data.all %>% filter(Outlet_Type==OutletTypes[i],is.na(Outlet_Size)) %>% nrow() >0){
data.all[data.all$Outlet_Type==OutletTypes[i] & is.na(data.all$Outlet_Size),'Outlet_Size']<- names(desc(table(data.all[data.all$Outlet_Type==OutletTypes[1] & !is.na(data.all$Outlet_Size) ,]$Outlet_Size)))[1]
}
}
#------------------------------------------------------------------------------------------
#dropping the unused factors
data.all$Item_Fat_Content <- droplevels(data.all$Item_Fat_Content)
train <- data.all %>% filter(flag=='train') %>% select(-flag)
test <- data.all %>% filter(flag=='test') %>% select(-flag)
# #BUILDING A LINEAR MODEL
# model <- glm(Item_Outlet_Sales ~ Item_Fat_Content+ Item_Weight + Item_Visibility + Item_Type+ Item_MRP + Outlet_Identifier + Outlet_Establishment_Year + Outlet_Size + Outlet_Location_Type + Outlet_Type, data = train)
#
# # GETTING THE PREDICTED VALUES
# predictedvalues <- predict(model,newdata = test)
#
# test <- cbind(test,predictedvalues)
#
# submission <- read.csv('SampleSubmission.csv')
#
# submission$Item_Outlet_Sales <- predictedvalues
#
# write.csv(submission,'PredictedValues.csv')
# Trying Random Forest
library(rpart)
library(rpart.plot)
library(randomForest)
ForestModel <- randomForest(Item_Outlet_Sales ~ Item_Fat_Content+ Item_Weight + Item_Visibility + Item_Type+ Item_MRP + Outlet_Identifier + Outlet_Establishment_Year + Outlet_Size + Outlet_Location_Type + Outlet_Type, data = train, ntree=200, nodesize=25)
predictedvalues <- predict(ForestModel,newdata = test)
test <- cbind(test,predictedvalues)
submission <- read.csv('SampleSubmission.csv')
submission$Item_Outlet_Sales <- predictedvalues
write.csv(submission,'PredictedValues.csv')
# cartModel <- rpart(Item_Outlet_Sales ~ Item_Fat_Content+ Item_Weight + Item_Visibility + Item_Type+ Item_MRP + Outlet_Identifier + Outlet_Establishment_Year + Outlet_Size + Outlet_Location_Type + Outlet_Type, data = train, minbucket=25)
#
# predictedvalues <- predict(ForestModel,newdata = test)
#
# test <- cbind(test,predictedvalues)
#
# submission <- read.csv('SampleSubmission.csv')
#
# submission$Item_Outlet_Sales <- predictedvalues
#
# write.csv(submission,'PredictedValues.csv')
